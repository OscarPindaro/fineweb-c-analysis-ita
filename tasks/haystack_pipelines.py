import json
from typing import Dict, List
from src.haystack.topic_pipeline import PromptVariables, TopicExtractionPipeline
from pathlib import Path
from haystack import Pipeline, Document
import pandas as pd

def create_topic_extraction_pipeline(product, model_id, system_prompt_path, ask_prompt_path, assistant_start="<classe=\"", stream_reaponse=False):
    system_prompt_path= Path(system_prompt_path)
    ask_prompt_path = Path(ask_prompt_path)
    assert system_prompt_path.exists() and system_prompt_path.is_file()
    assert ask_prompt_path.exists() and ask_prompt_path.is_file()
    print(ask_prompt_path)
    system_prompt = system_prompt_path.read_text()
    ask_prompt= ask_prompt_path.read_text()
    
    
    pipeline: Pipeline = TopicExtractionPipeline.create_pipeline(
        model_id=model_id,
        system_prompt=system_prompt,
        ask_prompt=ask_prompt,
        assistant_start=assistant_start,
        stream_response=stream_reaponse
    )
    product = Path(product)
    product.parent.mkdir(exist_ok=True, parents=True)
    pipeline.dump(product.open("w"))
    
def run_topic_extraction(product, upstream, prompt_vars_path, pipeline_upstream, update_categories: bool = True):

    """The idea is to get the dataframe generated by the tf-idf task
    and then ask to an llm the topic of the sample. 
    Then, the result + only the id is saved
    """
    pipeline_path = upstream[pipeline_upstream]
    pipeline: TopicExtractionPipeline = TopicExtractionPipeline(pipeline_path, update_categories=update_categories)
    # print(json.loads(prompt_vars_path), flush=True)
    prompt_vars = PromptVariables.load_from_file(prompt_vars_path)
    
    # now let's gather the data
    df = pd.read_parquet(upstream["tf_idf_keywords"]["dataset"])
    df = df
    samples_with_id = [(df["id"].iloc[i], _row_to_doc(df, i)) for i in range(len(df))]
    samples = [s[1] for s in samples_with_id]
    outs = pipeline.run(samples,prompt_vars)
    categories = outs["categories"]
    to_ret: List[Dict] = []
    for sample, category in zip(samples_with_id, categories):
        to_ret.append(
            {"id":sample[0],
             "category":category}
        )
    out_df = pd.DataFrame(to_ret)
    print(Path(product).suffix)
    if Path(product).suffix == ".parquet":
        out_df.to_parquet(product)
    elif Path(product).suffix == ".csv":
        out_df.to_csv(product)
    else:
        out_df.to_parquet(product)
def _row_to_doc(df, idx) -> Document:
    sample = Document(content=df.iloc[idx]["text"], meta={"quality":df["best_educational_value"].iloc[idx], "keywords":list(df["tfidf_keywords"].iloc[idx])})
    return sample